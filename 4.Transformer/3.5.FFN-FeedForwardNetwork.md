## Feed Forward Network
FFN（Feed Forward Network，前馈网络）块是用于神经网络的一种基本结构，通常应用于诸如 Transformer模型中的每个层内部。它由两个线性变换和一个非线性激活函数组成。

>FFN 计算公式

$$
F F N(x)=\operatorname{ReLU}\left(x W_1+b_1\right) W_2+b_2
$$


其中：
- $x$: 输入向量
- $W_1$, $W_2$: 分别是两个不同的权重矩阵
- $b_1$, $b_2$: 分别是两个偏置向量
- ReLU 是激活函数, 通常使用ReLU (Rectified Linear Unit) 或其他非线性激活函数

整个过程可以分为两步:
1. 首先对输入 $x$ 进行一次线性变换，计算 $x W_1+b_1$ ，然后通过激活函数（例如ReLU）进行非线性变换
2. 然后再进行一次线性变换, 得到最终输出

这一过程通常被视为在保持输入维度不变的情况下，进行一种投影操作，使得模型能够更好地表达复杂的特征。



>FFN (Feed Forward Network)
```py

class FeedForwardBlock(nn.Module):

    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:
        super().__init__()
        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1
        self.dropout = nn.Dropout(dropout)
        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2

    def forward(self, x):
        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)
        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))
```