#  One-Hot
>思考
- 2万个汉字，可以每个用一个数字去表示它吗？

## 1 Intro
One-Hot 表示是一种将离散的单词或符号转换为向量的方法。在自然语言处理中，它将每个单词表示为一个向量，其中只有一个位置为1，其余位置为0



<div align=center>
    <image src="imgs/onehot.png" width=500>
</div>


## 2 One-Hot 表示的优缺点
>优点
- 唯一表示: 每个字的 One-Hot 编码（向量），乘积为 0（即垂直/线性无关），意味着不能用其他向量表示
- 简单易理解：One-Hot 表示非常直观且容易实现，不需要复杂的计算或预训练

>缺点
- 高维稀疏性：如果语料库很大，One-Hot 向量的维度将会变得非常高，且绝大多数位置为0，导致数据的稀疏性。这会增加存储和计算的负担
- 缺乏语义信息：One-Hot 向量无法捕捉单词之间的任何语义关系。不同的单词之间的`距离（余弦相似度）`总是相同的，这意味着“cat”和“dog”与“cat”和“fish”之间的相似度无法区分
- 不能处理未登录词（OOV）：如果测试数据中出现了训练集中没有的单词（未登录词），One-Hot 表示无法处理这些新词
- 无法处理上下文信息：One-Hot 表示是静态的，无法根据上下文调整单词的表示，限制了其在复杂语言任务中的应用

>总结
- 虽然 One-Hot 表示在某些简单的任务中仍然有用，但由于其高维稀疏性和缺乏语义信息，现代自然语言处理方法更多地使用词向量（如 Word2Vec）或上下文敏感的词嵌入（如 BERT）来表示单词和处理文本。这些方法能够更有效地捕捉单词之间的语义关系，并在各种 NLP 任务中表现出更好的性能


## 3 训练 One-Hot

输入矩阵：$\text{Num}_{sentence}\times \text{Num}_{word} \times \text{Dim}_{one hot}$


## 4 Word Vector 词向量

为了解决 One-Hot 存储和表达的问题，我们想一下，假如，可以如下表示：

<div align=center>
    <image src="imgs/wordvec.png" width=700>
</div>
&emsp;

也就是说，向量中的元素可以是任意实数，那么试想一下，是不是就可以不需要那么多维，都可以表示很多词？

那么，我们如何获得中间的这个表示词的矩阵呢？答案是 `word2vec。`


<div align=center>
    <image src="imgs/3dim.png" width=700>
</div>