# Hugging Face Transformers

## AutoTokenizer

AutoTokenizer 是 Hugging Face 的 transformers 库中的一个实用工具，它用于从预训练模型中自动加载适当的分词器（Tokenizer）。分词器在自然语言处理（NLP）任务中非常重要，它负责将文本转换为模型可以处理的格式，如将文本拆分为词汇或子词，然后转换为对应的数值 ID。

### 1 AutoTokenizer 的主要特点
#### 1.1 自动选择合适的分词器
AutoTokenizer 可以根据给定的模型名称或路径自动加载适合的分词器类型。不同的预训练模型（如 BERT、GPT-2、T5 等）通常使用不同的分词器，例如 WordPiece、Byte-Pair Encoding (BPE) 等。AutoTokenizer 会根据模型的配置自动选择正确的分词器。

#### 1.2 支持多种模型
它支持许多流行的预训练模型，无论是基于词汇的模型（如 BERT），还是基于子词的模型（如 GPT 系列），都可以通过 AutoTokenizer 方便地加载。

#### 1.3 快速和慢速分词器
AutoTokenizer 支持加载快速分词器（use_fast=True）和慢速分词器。快速分词器通常由 Rust 编写，速度更快，性能更高；慢速分词器则是使用 Python 编写的。

#### 1.4 处理特殊标记
AutoTokenizer 处理特殊标记（如 `[CLS]`、`[SEP]` 等）时非常方便，它可以自动添加这些标记，或者根据需要自定义添加特殊标记。

#### 1.4 兼容性和扩展性
AutoTokenizer 兼容 Hugging Face 的各种模型，并且可以通过自定义选项（如 additional_special_tokens）进行扩展。

### 2 常见的使用场景
>从预训练模型加载分词器
- 加载 BERT 的基础模型（未加大小写区分）的分词器
```py
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

>分词和编码
- 将文本转换为模型可以直接输入的张量格式
```py
inputs = tokenizer("Hello, how are you?", return_tensors="pt")
```

>快速分词器的使用
- 加载快速分词器版本
```py
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased", use_fast=True)
```
